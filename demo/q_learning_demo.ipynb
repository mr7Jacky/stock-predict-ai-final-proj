{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "sys.path.insert(1, '../agent')\n",
    "sys.path.insert(1, '../price_pred')\n",
    "\n",
    "import stock_env\n",
    "from QLAgent import QNAgent\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file_data = 'AAPL.csv'\n",
    "env_name = 'StockEnv-v0'\n",
    "\n",
    "num_episodes = 1 # training epoches\n",
    "render_p = 10 # print frequency\n",
    "init_balance = 1000 # initial fund agent have\n",
    "\n",
    "len_obs = 70 # observation length, number of days the agent look back\n",
    "len_window = 100 # num of times trained each time\n",
    "interval = 1 # interval of validation\n",
    "overlap = 20 # overlapping between two consecutive training data \n",
    "batch_size = 1000 \n",
    "a = [i/10 for i in range(-4,5,1)]\n",
    "print(tuple(a))\n",
    "action_list=tuple(a)\n",
    "seed = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct environment and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "# Read data you want to use for trading\n",
    "train_data, test_data = get_data(f'../data/{name_file_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instant\n",
    "env = gym.make(env_name, train_data=train_data, eval_data=test_data, \n",
    "               len_obs=len_obs, len_window=len_window, init_balance=init_balance,\n",
    "               action_list=action_list)\n",
    "env.seed(seed)\n",
    "print(f'Observation space: {env.observation_space}')\n",
    "print(f'Action space: {env.action_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent\n",
    "agent = QNAgent(env.action_space.n, env.observation_space.shape, \n",
    "                discount_rate=0.5, learning_rate=0.01, epsilon=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_ep = 0\n",
    "train_statistics = pd.DataFrame()\n",
    "test_statistics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worth = []\n",
    "losses = []\n",
    "for ep in range(init_ep, num_episodes):\n",
    "    _, _, loss = get_performance(env, agent, train_data=True, training=True, batch_size=batch_size)\n",
    "    if (ep % render_p) == 0:\n",
    "        env.render(ep)\n",
    "    worth.append(env.net_worth)\n",
    "    losses = np.concatenate((losses,loss))\n",
    "    if ep % interval == 0:\n",
    "        overlap = overlap\n",
    "        results_train = np.empty(shape=(0, 3))\n",
    "        results_test = np.empty(shape=(0, 3))\n",
    "\n",
    "        size_test = ((len(env.eval_data)-env.len_obs-env.len_window) // overlap)+1\n",
    "        cagr_train, vol_train, _ = get_performance(env, agent, train_data=True, training=False, batch_size=size_test)\n",
    "        results_train = np.array([np.tile(ep, size_test), cagr_train, vol_train]).transpose()\n",
    "\n",
    "        cagr_test, vol_test, _ = get_performance(env, agent, train_data=False, training=False, overlap=overlap, batch_size=size_test)\n",
    "        results_test = np.array([np.tile(ep, size_test), cagr_test, vol_test]).transpose()\n",
    "\n",
    "        train_statistics = pd.concat([train_statistics, pd.DataFrame(results_train, columns=['epoch', 'cagr','volatility'])])\n",
    "        test_statistics = pd.concat([test_statistics, pd.DataFrame(results_test, columns=['epoch', 'cagr','volatility'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Worth histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(np.array(worth).flatten(), bins=range(500,2000,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean worth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = num_episodes\n",
    "threshold = 5000\n",
    "worth_mean = np.mean(worth,axis=-1)\n",
    "k = np.split(worth_mean, precision)\n",
    "k = np.mean(k, axis = -1)\n",
    "#k = [len(np.where(i > threshold)[0]) for i in worth]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(k,'-')\n",
    "#plt.boxplot(np.transpose(worth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ql_agent(agent, filename):\n",
    "    os.mkdir(filename)\n",
    "    param = (agent.action_size, agent.state_size, agent.epsilon, agent.discount_rate, agent.learning_rate, agent.optimizer)\n",
    "    pickle.dump(param, open(filename + '/param', 'wb'))\n",
    "    agent.model.save_weights(filename + '/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ql_agent(agent, 'ql_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ql_agent(filename):\n",
    "    # Obtain parameter\n",
    "    param = pickle.load(open(filename + '/param', 'rb'))\n",
    "    # Initialize Agent\n",
    "    a = QNAgent(param[0], param[1])\n",
    "    # Set parameter\n",
    "    a.set_param(param)\n",
    "    # Load model weight\n",
    "    a.model.load_weights(filename+'/model')\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = load_ql_agent('ql_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
